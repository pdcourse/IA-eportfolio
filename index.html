<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>E-Portfolio Intelligent Agents 2025</title>
  <style>
    body {
      margin: 0;
      font-family: "Helvetica Neue", "Segoe UI", Tahoma, Arial, sans-serif;
      line-height: 1.6;
      background: #f4f5f7;
      color: #333;
    }

    header {
      background: #e0e6ed;
      padding: 1rem 2rem;
      border-bottom: 1px solid #c8d0d9;
    }

    header h1 {
      margin: 0;
      font-size: 1.6rem;
      color: #2f4f66;
      text-align: center;
    }

    nav {
      max-width: 250px;
      margin: 2rem auto;
      padding: 1rem;
      background: #ffffff;
      border: 1px solid #dcdfe3;
      border-radius: 8px;
    }

    nav ul {
      list-style: none;
      padding: 0;
      margin: 0;
    }

    nav li {
      margin-bottom: 0.8rem;
    }

    nav a {
      display: block;
      text-decoration: none;
      color: #2f4f66;
      padding: 0.5rem 0.8rem;
      border-radius: 4px;
      transition: background 0.2s;
    }

    nav a:hover {
      background: #f0f2f5;
    }

    section {
      padding: 40px 20px;
      max-width: 800px;
      margin: 20px auto;
      background: #fff;
      border: 1px solid #dcdfe3;
      border-radius: 8px;
    }

    section h2 {
      margin-top: 0;
      color: #2f4f66;
    }

    .back-link {
      margin-top: 20px;
      text-align: right;
    }

    .back-link a {
      color: #2f4f66;
      font-size: 0.9rem;
      text-decoration: none;
      font-weight: bold;
    }

    .back-link a:hover {
      text-decoration: underline;
    }
  </style>
</head>
<body>
  <header id="top">
    <h1>E-Portfolio Intelligent Agents 2025</h1>
  </header>

  <nav>
    <ul>
      <li><a href="#discussion1">Discussion 1</a></li>
      <li><a href="#discussion2">Discussion 2</a></li>
      <li><a href="#discussion3">Discussion 3</a></li>
      <li><a href="#teamproject">Team Project</a></li>
      <li><a href="#unit6">Unit 6: Agent Dialogues</a></li>
      <li><a href="#unit8">Unit 8: Understanding NLP</a></li>
      <li><a href="#unit10">Unit 10: Deep Learning</a></li>
      <li><a href="#wiki">Module Wiki Contributions</a></li>
    </ul>
  </nav>

  <section id="discussion1">
    <h2>Discussion 1: Agent Based Systems</h2>
    <p>This discussion highlighted how intelligent agents have evolved, from early theory (Wooldridge and Jennings, 1995) to the more recent use of large language models. I was struck by the opportunities these systems create, such as emergent behaviours and new applications, but also by the challenges they face. Issues like context sensitivity, knowledge limits and governance (Xi et al., 2023; Gao et al., 2024) made me think about how difficult it is to deploy them reliably. My peer’s point on retrieval augmented generation felt especially relevant, since evidence shows it can improve accuracy in applied fields (Woo et al., 2025). This made me reflect on how progress in intelligent agents is not only technical but also about finding designs that are dependable in practice.</p>

<p><strong>References</strong></p>

<ul>
  <li>Gao, C. et al. (2024) ‘Large language models empowered agent-based modeling and simulation: a survey and perspectives’, Humanities and Social Sciences Communications.</li>

<li>Woo, J.J. et al. (2025) ‘Custom Large Language Models improve accuracy: Comparing Retrieval Augmented Generation and artificial intelligence agents to noncustom models for evidence-based medicine’, Arthroscopy.</li>

<li>Wooldridge, M.J. and Jennings, N.R. (1995) ‘Intelligent agents: theory and practice’, Knowledge Engineering Review.</li>

<li>Xi, Z. et al. (2023) ‘The rise and potential of large language model based agents: A survey’, arXiv. doi:10.48550/ARXIV.2309.07864.</li>
    <div class="back-link"><a href="#top">Back to navigation</a></div>
  </section>

  <section id="discussion2">
    <h2>Discussion 2: Agent Communication Languages</h2>
      <h2>Agent Communication Languages</h2>
  <p>In this discussion we considered how agent communication languages such as KQML differ from more traditional programming approaches. I found it useful to see how performatives like <em>ask</em> or <em>tell</em> can explicitly express intent and support interactions such as negotiation or cooperation (Finin and Labrou, 1999). This helped me appreciate why ACLs are valuable in dynamic, heterogeneous environments where agents need to adapt and coordinate flexibly (Labrou and Finin, 1998).</p>

  <p>At the same time, I noticed that KQML brings its own problems. The lack of clear semantics across platforms can lead to ambiguity (Mayfield et al., 1996), and its bias toward certain types of speech acts seems limiting (Bouzouba, 1998). My peer Ana-Maria’s point about semantic ambiguity stopping collaboration was very convincing, especially when she connected it to the challenge of ensuring reliable commitments between agents (Cohen and Levesque, 1995). I also found it interesting that both Ana-Maria and Paul pointed to the potential of combining ACLs with large language models, since work like Gatti et al. (2025) suggests this hybrid approach could improve adaptability and negotiation.</p>

  <p>This made me reflect on how agent communication research still matters today, but also how it might need to evolve by incorporating newer AI methods to stay relevant.</p>

  <p><strong>References</strong></p>
  <ul>
    <li>Bouzouba, K. (1998) 'CG KQML+: An Agent Communication Language and its use in a Multi-Agent System', <em>CEUR Workshop Proceedings</em>.</li>
    <li>Cohen, P.R. and Levesque, H.J. (1995) 'Communicative Actions for Artificial Agents', <em>Proceedings of the First International Conference on Multi-Agent Systems (ICMAS 1995)</em>.</li>
    <li>Finin, T. (1995) 'Facilitating agent interaction', <em>International Journal of Applied Intelligence</em>.</li>
    <li>Finin, T. and Labrou, Y. (1999) 'Agent Communication Languages KQML', <em>Tutorial Presentation</em>.</li>
    <li>Gatti, A., Mascardi, V. and Ferrando, A. (2025) 'ChatBDI: Think BDI, Talk LLM', <em>Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2025)</em>.</li>
    <li>Labrou, Y. and Finin, T. (1998) 'Semantics and Conversations for an Agent Communication Language', <em>arXiv preprint</em>.</li>
    <li>Mayfield, J., Labrou, Y. and Finin, T. (1996) 'Evaluation of KQML as an Agent Communication Language', <em>Lecture Notes in Computer Science</em>.</li>
  </ul>
    <div class="back-link"><a href="#top">Back to navigation</a></div>
  </section>

  <section id="discussion3">
    <h2>Discussion 3: Deep Learning</h2>
    <p>  <h2>Deep Learning</h2>
  <p>This discussion focused on the impact of deep learning in creating media such as text, images and music. What stood out to me is how quickly questions of authorship and ownership arise. Generative systems are built on human-created data, but it is often unclear how that input links to the outputs. As both Lim (2023) and Al-Busaidi (2024) argue, copyright law struggles to keep up with these blurred boundaries. The U.S. Copyright Office (2025) even maintains that fully autonomous AI works cannot be copyrighted unless there is clear human creative input. I found this position important because it shows how legal systems are still catching up with the technology.</p>

  <p>Another area that I reflected on was authenticity and public trust. Deepfakes and other synthetic content can create real risks for journalism and communication, reducing credibility when audiences are unsure of content’s origin (Lundberg, 2024; Raemy, 2025; Lundberg and Mozelius, 2025). The peer point about safeguards such as watermarking and disclosure felt particularly relevant. These approaches seem essential if generative systems are to be accepted in sensitive fields.</p>

  <p>Bias in training data was also raised as a concern, with Ukanwa (2024) and Wei et al. (2025) showing how inequities can be reproduced or even amplified. This made me think about how technical fixes are not enough, and how interdisciplinary oversight, including audits and documentation, might be required. At the same time, there are also benefits. Doshi et al. (2024) show that generative tools can raise the quality of creative work and help newcomers participate more easily. For me, the balance lies in maximising these benefits while putting safeguards in place to address ownership, trust and bias.</p>

  <p><strong>References</strong></p>
  <ul>
    <li>Al-Busaidi, A. S. (2024). Investigating the impact of generative artificial intelligence on creative industries. <em>Heliyon</em>.</li>
    <li>Doshi, A. R., et al. (2024). Generative AI enhances individual creativity but reduces variance. <em>Science Advances</em>.</li>
    <li>Lim, D. (2023). Generative AI and copyright. <em>Journal of Intellectual Property Law & Practice</em>.</li>
    <li>Lundberg, E. (2024). The potential effects of deepfakes on news media. <em>AI & Society</em>.</li>
    <li>Lundberg, E. and Mozelius, P. (2025). The potential effects of deepfakes on news media and entertainment. <em>AI & Society</em>, 40, pp. 2159–2170.</li>
    <li>Raemy, P. (2025). Deepfakes and journalism. <em>Journalism Studies</em>.</li>
    <li>Ukanwa, K. (2024). Algorithmic bias and social science integration. <em>Journal of Behavioral and Experimental Economics</em>.</li>
    <li>United States Copyright Office (2025). <em>Copyright and Artificial Intelligence, Part 2: Copyrightability: A Report of the Register of Copyrights</em>. Washington, DC: U.S. Copyright Office.</li>
    <li>Wei, X., Kumar, N. and Zhang, H. (2025). Addressing bias in generative AI: Challenges and research opportunities in information management. <em>Information & Management</em>, 62(2), 104103.</li>
  </ul>
</p>
    <div class="back-link"><a href="#top">Back to navigation</a></div>
  </section>

  <section id="teamproject">
    <h2>Team Project</h2>
    <p>In our group project we explored how autonomous agents could improve cybersecurity by pre-screening files before users download them. The idea was to build a system that combines a browser extension with a verification service, so that suspicious files can be intercepted early and checked against scanning rules and lightweight machine learning models.</p>
    <p></p>
  One of my main contributions was on the design of the server-side service. I worked on outlining how Python could be used with libraries such as yara-python and pytorch for both deterministic and anomaly-based detection, and how a PostgreSQL database could help with structured reporting and auditing due to its relational design with the possibility to have NOSQL-like JSON columns. My two team members proposed the use of a Chrome extension as the agent’s point of interaction with users. I found it interesting to see how these two parts complemented each other, since the server logic and the extension together created a clear flow from interception to analysis.</p>
  <p>Reflecting on the project, I think we were able to show how autonomous verification agents can provide a proactive layer of defence that acts earlier than traditional endpoint tools that do the analysis once the download has already been completed.</p>
    <div class="back-link"><a href="#top">Back to navigation</a></div>
  </section>

  <section id="unit6">
    <h2>Unit 6: Agent Dialogues</h2>
    <p>I used KQML for the communication layer because its performatives make intentions explicit. <em>ask-one</em> and <em>tell</em> support factual queries with clear expectations, while <em>achieve</em> captures a delegated goal that an actuator can try to satisfy. KIF was selected for the content so that domain predicates are both machine interpretable and suitable for rule checking and audit trails. I separated the vocabulary into two ontologies, <code>energy-monitoring</code> for sensing and <code>energy-control</code> for actuation, which keeps validation simpler and supports permissions that differ for reading and writing.</p>

  <p>The interaction models a practical control loop. BuildingAgent requests a measurement, applies policy locally, then asks MeterAgent to carry out a load reduction. This mirrors building operations where measurement, decision and action often live in different services. I kept the dialogue concise to emphasise traceability and testability. The same pattern could be extended to proposals and counter proposals if several devices must share a reduction target, but this minimal exchange already demonstrates how intent, data and action stay cleanly separated.</p>

  <p><strong>Dialogue</strong></p>

  <pre><code>(kqml
  :performative ask-one
  :sender BuildingAgent
  :receiver MeterAgent
  :language KIF
  :ontology energy-monitoring
  :content
    (current-consumption building-01 ?kw))

(kqml
  :performative tell
  :sender MeterAgent
  :receiver BuildingAgent
  :language KIF
  :ontology energy-monitoring
  :content
    (current-consumption building-01 125))

(kqml
  :performative achieve
  :sender BuildingAgent
  :receiver MeterAgent
  :language KIF
  :ontology energy-control
  :content
    (reduce-load building-01 20))

(kqml
  :performative tell
  :sender MeterAgent
  :receiver BuildingAgent
  :language KIF
  :ontology energy-control
  :content
    (load-reduction building-01 20 success))</code></pre>
    <div class="back-link"><a href="#top">Back to navigation</a></div>
  </section>

  <section id="unit8">
    <h2>Unit 8: Understanding NLP</h2>
    <p>For this task I produced constituency parse trees for three English sentences. The trees show how words group into larger units such as noun phrases (NP), verb phrases (VP) and prepositional phrases (PP). This hierarchical structure makes it easier to see how meaning is built up, which is important for many natural language processing applications in intelligent systems.</p>

  <p><strong>1. The government raised interest rates.</strong></p>
  <pre><code>(S
  (NP (DT The) (NN government))
  (VP (VBD raised)
    (NP (NN interest) (NNS rates))))</code></pre>

  <p><strong>2. The internet gives everyone a voice.</strong></p>
  <pre><code>(S
  (NP (DT The) (NN internet))
  (VP (VBZ gives)
    (NP (NN everyone))
    (NP (DT a) (NN voice))))</code></pre>

  <p><strong>3. The man saw the dog with the telescope.</strong></p>
  <pre><code>(S
  (NP (DT The) (NN man))
  (VP (VBD saw)
    (NP
      (NP (DT the) (NN dog))
      (PP (IN with)
          (NP (DT the) (NN telescope))))))</code></pre>
    <div class="back-link"><a href="#top">Back to navigation</a></div>
  </section>


  <section id="unit10">
    <h2>Unit 10: Deep Learning</h2>
  <h2>Deep Learning for Medical Imaging Diagnosis</h2>

  <p><strong>Overview of the technology.</strong> I chose deep learning for medical imaging because it is already changing how clinicians read scans and because I am considering to dedicate my computing thesis to this field as well.</p>

<p>Convolutional neural networks can triage and detect disease in X-rays and mammograms with performance that in some cases approaches or exceeds clinical readers, which suggests a path to earlier detection and more consistent decisions (McKinney et al., 2020; Rajpurkar et al., 2018; Esteva et al., 2017). Recent reviews show how this family of models now supports core imaging tasks such as classification, detection and segmentation across many specialties (Litjens et al., 2017).</p>

  <p><strong>How it works in brief.</strong> In practice, models learn from large labelled image datasets using supervised training on architectures such as CNNs. Pretraining on general images and fine-tuning on medical data helps when datasets are small, while evaluation uses metrics like AUC to compare against expert readers (Litjens et al., 2017; Rajpurkar et al., 2018). Systems can then be deployed as a second reader or triage aid. A well known example is an AI for screening mammography that reduced false positives and false negatives compared with standard reading workflows in UK and US test sets (McKinney et al., 2020). To protect privacy and improve generalisation across hospitals, federated learning trains models locally and shares model updates rather than raw data, which can reduce data-sharing risks while preserving performance (Rieke et al., 2020).</p>

  <p><strong>Socio-technical impacts.</strong> I see clear public health benefits if these tools shorten waiting lists, catch cancers earlier and reduce variation between readers. At the same time, ethics and governance matter because imaging AI can embed bias, reduce transparency and shift accountability if responsibilities are unclear. Multisociety guidance in radiology stresses wellbeing, fairness, transparency and ongoing human responsibility for decisions, which I support as practical guardrails for deployment (Geis et al., 2019). Privacy is another concern because medical images can be re-identifiable. This is why techniques such as federated learning and careful auditing feel essential to me for safe scaling beyond single centres (Rieke et al., 2020; Topol, 2019). Overall, my view is that imaging AI can deliver social good when paired with rigorous validation, privacy-preserving training and clear lines of clinical accountability.</p>

  <p><strong>References</strong></p>
  <ul>
    <li>Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M. and Thrun, S. (2017) ‘Dermatologist-level classification of skin cancer with deep neural networks’, <em>Nature</em>.https://doi.org/10.1038/nature21056.</li>
    <li>Geis, J.R., Brady, A., Wu, C.C., Spencer, J., Ranschaert, E., Jaremko, J.L. <em>et&nbsp;al.</em> (2019) ‘Ethics of artificial intelligence in radiology: summary of the joint European and North American multisociety statement’, <em>Insights into Imaging</em>. https://doi.org/10.1186/s13244-019-0785-8.</li>
    <li>Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A., Ciompi, F., Ghafoorian, M. <em>et&nbsp;al.</em> (2017) ‘A survey on deep learning in medical image analysis’, <em>Medical Image Analysis</em>. https://doi.org/10.1016/j.media.2017.07.005.</li>
    <li>McKinney, S.M., Sieniek, M., Godbole, V., Godwin, J., Antropova, N., Ashrafian, H. <em>et&nbsp;al.</em> (2020) ‘International evaluation of an AI system for breast cancer screening’, <em>Nature</em>. https://doi.org/10.1038/s41586-019-1799-6.</li>
    <li>Rajpurkar, P., Irvin, J., Ball, R.L., Zhu, K., Yang, B., Mehta, H. <em>et&nbsp;al.</em> (2018) ‘Deep learning for chest radiograph diagnosis: a retrospective comparison of the CheXNeXt algorithm to practicing radiologists’, <em>PLOS Medicine</em>. https://doi.org/10.1371/journal.pmed.1002686.</li>
    <li>Rieke, N., Hancox, J., Li, W., Milletarì, F., Roth, H.R., Albarqouni, S. <em>et&nbsp;al.</em> (2020) ‘The future of digital health with federated learning’, <em>npj Digital Medicine</em>. https://doi.org/10.1038/s41746-020-00323-1.</li>
    <li>Topol, E.J. (2019) ‘High-performance medicine: the convergence of human and artificial intelligence’, <em>Nature Medicine</em>. https://doi.org/10.1038/s41591-018-0300-7.</li>
  </ul>

    <div class="back-link"><a href="#top">Back to navigation</a></div>
  </section>
  <section id="wiki">
    <h2>Module Wiki Contributions</h2>
    <p>I contributed entries on the agent control loop, hybrid agents, KQML, NLP, reactive agents and symbolic reasoning agents to the module wiki because I felt it was a good way to consolidate what I had learned and to provide clear definitions for anyone else who might want a quick reference. Writing them helped me structure my own understanding and practise expressing technical concepts in a concise way.</p>

<p>Unfortunately, it seems that the wiki has not been actively used by others on the course. While this made it feel a bit one-sided, I still found value in making the contributions because it gave me a chance to revise and clarify core ideas in agent systems. For me, the exercise reinforced that sometimes the act of writing for others is just as useful for consolidating my own learning.</p>
    <div class="back-link"><a href="#top">Back to navigation</a></div>
  </section>
</body>
</html>
